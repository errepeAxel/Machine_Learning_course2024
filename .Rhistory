)
library(palmerpenguins)
library(corrr)
library(GGally)
library(recipes)
library(tidytext)
library(dplyr)
library(tidyr)
library(ggplot2)
theme_set(theme_minimal())
library(ggplot2)
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
component)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
# Load the corrr library
library(corrr)
# Select specific columns from the "penguins" dataset and compute the correlation matrix
penguins_corr <- penguins %>%
dplyr::select(body_mass_g, ends_with("_mm")) %>%
correlate() %>%
rearrange()
# Display the resulting correlation matrix
penguins_corr
penguins %>%
select(species, body_mass_g, ends_with("_mm")) %>%
GGally::ggpairs(aes(color = species),
columns = c("flipper_length_mm", "body_mass_g",
"bill_length_mm", "bill_depth_mm")) +
scale_colour_manual(values = c("darkorange","purple","cyan4")) +
scale_fill_manual(values = c("darkorange","purple","cyan4"))
library(ggplot2)
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
component)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
library(ggplot2)
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
str(pinguin_pca)
str(penguin_pca)
library(embed)
# Create a recipe for preprocessing and PCA transformation
penguin_recipe <-
recipe(~., data = penguins) %>%  # Create a recipe
update_role(species, island, sex, year, new_role = "id") %>%  # Update roles
step_naomit(all_predictors()) %>%  # Handle missing values
step_normalize(all_predictors()) %>%  # Normalize predictors
step_umap(all_predictors(), id = "umap") %>%  # Apply PCA
prep()  # Prepare the recipe
# Apply the recipe and extract the PCA results
penguin_umap <-
penguin_recipe %>%
juice(id = "umap")
library(embed)
# Create a recipe for preprocessing and PCA transformation
penguin_recipe <-
recipe(~., data = penguins) %>%  # Create a recipe
update_role(species, island, sex, year, new_role = "id") %>%  # Update roles
step_naomit(all_predictors()) %>%  # Handle missing values
step_normalize(all_predictors()) %>%  # Normalize predictors
step_umap(all_predictors(), id = "umap") %>%  # Apply PCA
prep()  # Prepare the recipe
# Apply the recipe and extract the PCA results
penguin_umap <-
penguin_recipe %>%
juice()
# Display the PCA results
penguin_umap
library(ggplot2)
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
component)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
library(ggplot2)
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
component)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
ggplot(penguin_umap, aes(x = umap1, y = umap2)) +
geom_point(aes(color = species)) +
labs(title = "UMAP Plot of Penguins Dataset", x = "UMAP Dimension 1", y = "UMAP Dimension 2") +
theme_minimal()
ggplot(penguin_umap, aes(x = umap1, y = umap2)) +
geom_point(aes(color = species)) +
labs(title = "UMAP Plot of Penguins Dataset", x = "UMAP Dimension 1", y = "UMAP Dimension 2") +
theme_minimal()
ggplot(penguin_umap, aes(x = UMAP1, y = UMAP2)) +
geom_point(aes(color = species)) +
labs(title = "UMAP Plot of Penguins Dataset", x = "UMAP Dimension 1", y = "UMAP Dimension 2") +
theme_minimal()
penguin_umap %>%
mutate(terms = tidytext::reorder_within(terms,
abs(value),
component)) %>%
ggplot(aes(abs(value), terms, fill = value > 0)) +
geom_col() +
facet_wrap(~component, scales = "free_y") +
tidytext::scale_y_reordered() +
scale_fill_manual(values = c("#b6dfe2", "#0A537D")) +
labs(
x = "Absolute value of contribution",
y = NULL, fill = "Positive?"
)
ggplot(penguin_umap, aes(x = UMAP1, y = UMAP2)) +
geom_point(aes(color = species)) +
labs(title = "UMAP Plot of Penguins Dataset", x = "UMAP Dimension 1", y = "UMAP Dimension 2") +
theme_minimal()
library(tidymodels)
library(tune)
library(AmesHousing)
install.packages("AmesHousing")
library(tidymodels)
library(tune)
library(AmesHousing)
# ------------------------------------------------------------------------------
ames <- make_ames()
set.seed(4595)
data_split <- initial_split(ames, strata = "Sale_Price")
ames_train <- training(data_split)
set.seed(2453)
rs_splits <- vfold_cv(ames_train, strata = "Sale_Price")
# ------------------------------------------------------------------------------
ames_rec <-
recipe(Sale_Price ~ ., data = ames_train) %>%
step_log(Sale_Price, base = 10) %>%
step_YeoJohnson(Lot_Area, Gr_Liv_Area) %>%
step_other(Neighborhood, threshold = .1)  %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_ns(Longitude, deg_free = tune("lon")) %>%
step_ns(Latitude, deg_free = tune("lat"))
knn_model <-
nearest_neighbor(
mode = "regression",
neighbors = tune("K"),
weight_func = tune(),
dist_power = tune()
) %>%
set_engine("kknn")
ames_wflow <-
workflow() %>%
add_recipe(ames_rec) %>%
add_model(knn_model)
ames_set <-
extract_parameter_set_dials(ames_wflow) %>%
update(K = neighbors(c(1, 50)))
set.seed(7014)
ames_grid <-
ames_set %>%
grid_max_entropy(size = 10)
ames_grid_search <-
tune_grid(
ames_wflow,
resamples = rs_splits,
grid = ames_grid
)
install.packages("kknn")
library(tidymodels)
library(tune)
library(AmesHousing)
library(kknn)
# ------------------------------------------------------------------------------
ames <- make_ames()
set.seed(4595)
data_split <- initial_split(ames, strata = "Sale_Price")
ames_train <- training(data_split)
set.seed(2453)
rs_splits <- vfold_cv(ames_train, strata = "Sale_Price")
# ------------------------------------------------------------------------------
ames_rec <-
recipe(Sale_Price ~ ., data = ames_train) %>%
step_log(Sale_Price, base = 10) %>%
step_YeoJohnson(Lot_Area, Gr_Liv_Area) %>%
step_other(Neighborhood, threshold = .1)  %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_ns(Longitude, deg_free = tune("lon")) %>%
step_ns(Latitude, deg_free = tune("lat"))
knn_model <-
nearest_neighbor(
mode = "regression",
neighbors = tune("K"),
weight_func = tune(),
dist_power = tune()
) %>%
set_engine("kknn")
ames_wflow <-
workflow() %>%
add_recipe(ames_rec) %>%
add_model(knn_model)
ames_set <-
extract_parameter_set_dials(ames_wflow) %>%
update(K = neighbors(c(1, 50)))
set.seed(7014)
ames_grid <-
ames_set %>%
grid_max_entropy(size = 10)
ames_grid_search <-
tune_grid(
ames_wflow,
resamples = rs_splits,
grid = ames_grid
)
set.seed(2082)
ames_iter_search <-
tune_bayes(
ames_wflow,
resamples = rs_splits,
param_info = ames_set,
initial = ames_grid_search,
iter = 15
)
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(dotwhisker)
install.packages("dotwhisker")
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(dotwhisker)
library(vip)
install.packages("vip")
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(dotwhisker)
library(vip)
tidymodels_prefer()
data(ames)
set.seed(123)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
View(ames)
# If you do one train/test split
data_split <- initial_split(ames, strata = "Sale_Price", prop = 0.75) #Create Train/Test set
View(data_split)
ames_train <- training(data_split) # Fit model to this
ames_test  <- testing(data_split) # Don't use until evaluating final model
lm_spec <-
linear_reg() %>%  # Specify Model and Engine
set_engine( engine = 'lm') %>%
set_mode('regression')
lm_rec <- recipe(Sale_Price ~ Lot_Area + Year_Built +  House_Style + Gr_Liv_Area + Fireplaces, data = ames_train) %>%
step_lincomb(all_numeric_predictors()) %>% # Specify Formula and Preprocessing Recipe
step_zv(all_numeric_predictors()) %>%
step_mutate(Gr_Liv_Area = Gr_Liv_Area/100, Lot_Area = Lot_Area/100) %>%
step_mutate(Fireplaces = Fireplaces > 0) %>%
step_cut(Year_Built, breaks = c(0, 1950, 1990, 2020)) %>%
step_other(House_Style,threshold = .1) %>%
step_dummy(all_nominal_predictors())
train_prep <- lm_rec %>%
prep() %>%
bake(new_data = ames_train) # Pre-process Training Data
ames_wf <- workflow() %>% # Create Workflow (Recipe + Model Spec)
add_recipe(lm_rec) %>%
add_model(lm_spec)
lm_fit_train <- ames_wf %>%
fit(data = ames_train)  # Fit Model to Training Data
train_prep %>%
select(Sale_Price) %>%
bind_cols( predict(lm_fit_train, ames_train) ) %>%
metrics(estimate = .pred, truth = Sale_Price)  # Calculate Training metrics
lm_fit_train %>%
tidy() # Model Coefficients from Trained Model
library(dotwhisker)
tidy(lm_fit_train) %>%  # Viz of Trained Model Coef
dwplot(dot_args = list(size = 2, color = "black"),
whisker_args = list(color = "black"),
vline = geom_vline(xintercept = 0, color = "grey50", linetype = 2))
ames_cv <- vfold_cv(ames_train, v = 10, strata = Sale_Price) # Create 10 Folds of Training Data for CV
lm_fit_cv <- fit_resamples(ames_wf, # Fit Model to 10 Folds of Training Data
resamples = ames_cv,
metrics = metric_set(rmse, mae, rsq))
lm_fit_cv %>% collect_metrics() # Evaluate Trained Model using CV
lm_fit_test <- last_fit(ames_wf,
split = data_split)
lm_fit_test %>%
collect_metrics() #Evaluation on Test Data
library(vip)
conflicted::conflict_prefer("vi", "vip")
mod <- lm_fit_train %>% extract_fit_engine()
vi(mod, method = 'permute', target = 'Sale_Price', metric = 'rmse', train = train_prep, pred_wrapper = predict)
vip(mod, method = 'permute', target = 'Sale_Price', metric = 'rmse', train = train_prep, pred_wrapper = predict) + theme_classic()
#mod <- lm_fit_train %>% extract_fit_engine()
mod %>% check_model()
#mod <- lm_fit_train %>% extract_fit_engine()
mod %>% check_model()
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(dotwhisker)
library(vip)
#mod <- lm_fit_train %>% extract_fit_engine()
mod %>% check_model()
#mod <- lm_fit_train %>% extract_fit_engine()
mod %>% check_model()
#mod <- lm_fit_train %>% extract_fit_engine()
library(performance)
mod %>% check_model()
# Create Cross-Validation Folds
ames_cv <- vfold_cv(ames_train, v = 10, strata = Sale_Price) # Create 10 Folds of Training Data for CV
# Fit Model to Cross-Validation Folds and Evaluate Metrics
lm_fit_cv <- fit_resamples(ames_wf, # Fit Model to 10 Folds of Training Data
resamples = ames_cv,
metrics = metric_set(rmse, mae, rsq))
detach("package:performance", unload = TRUE)
# Create Cross-Validation Folds
ames_cv <- vfold_cv(ames_train, v = 10, strata = Sale_Price) # Create 10 Folds of Training Data for CV
# Fit Model to Cross-Validation Folds and Evaluate Metrics
lm_fit_cv <- fit_resamples(ames_wf, # Fit Model to 10 Folds of Training Data
resamples = ames_cv,
metrics = metric_set(rmse, mae, rsq))
# Create Cross-Validation Folds
ames_cv <- vfold_cv(ames_train, v = 10, strata = Sale_Price) # Create 10 Folds of Training Data for CV
# Fit Model to Cross-Validation Folds and Evaluate Metrics
lm_fit_cv <- fit_resamples(ames_wf, # Fit Model to 10 Folds of Training Data
resamples = ames_cv,
metrics = metric_set(rmse, mae, rsq))
# Apply Model to Test Data
lm_fit_test <- last_fit(ames_wf,
split = data_split)
# Collect Evaluation Metrics on Test Data
lm_fit_test %>%
collect_metrics() #Evaluation on Test Data
library(vip)
# Resolve Namespace Conflict
conflicted::conflict_prefer("vi", "vip")
# Extract Fit Engine Information
mod <- lm_fit_train %>% extract_fit_engine()
#mod <- lm_fit_train %>% extract_fit_engine()
library(performance)
mod %>% check_model()
.rs.restartR()
?taxi
detach("package:performance", unload = TRUE)
?taxi
DataExplorer::create_report(taxi)
devtools:::run_examples()
library(parsnip)
devtools:::run_examples()
logistic_reg()
#> Logistic Regression Model Specification (classification)
#>
#> Computational engine: glm
logistic_reg() %>%
set_engine("glmnet")
#> Logistic Regression Model Specification (classification)
#>
#> Computational engine: glmnet
decision_tree() %>%
set_mode("classification")
#> Decision Tree Model Specification (classification)
#>
#> Computational engine: rpart
logistic_reg() %>%
set_engine("glm")
#> Logistic Regression Model Specification (classification)
#>
#> Computational engine: glmnet
logistic_reg() %>%
set_engine("glm")
decision_tree() %>%
set_mode("classification")
set.seed(123)
taxi_split <- initial_split(taxi)
taxi_split
#> <Training/Testing/Total>
#> <7500/2500/10000>
taxi_train <- training(taxi_split)
taxi_test <- testing(taxi_split)
set.seed(123)
taxi_split <- initial_split(taxi, prop = 0.8)
taxi_train <- training(taxi_split)
taxi_test <- testing(taxi_split)
nrow(taxi_train)
#> [1] 8000
nrow(taxi_test)
#> [1] 2000
set.seed(123)
initial_validation_split(taxi, prop = c(0.6, 0.2))
set.seed(123)
taxi_split <- initial_split(taxi, prop = 0.8, strata = tip)
taxi_split
# Model
logistic_reg()
tree_spec <-
decision_tree(cost_complexity = 0.002) %>%
set_mode("classification")
workflow() %>%
add_formula(tip ~ .) %>%
add_model(tree_spec) %>%
fit(data = taxi_train)
dim(data)
library(readr)
data <- read_csv("microarray_expression_data.csv", col_names = TRUE)
dim(data)
str(data)
dim(data)
dim(data)
str(data)
dim(data)
str(data)
View(data)
help("separate")
library(tidyr)
data_clean <- separate(data = data, col = NAME, into = c("Name", "Function", "Details", "Mutation", "Position"), sep = "\\|\\|", remove = T)
help(mutate)
help(mutate)
library(dplyr)
library(stringr)
data_clean <- data_clean %>%
mutate(Name = str_squish(Name))
View(data_clean)
data_clean <- data_clean %>%
select(c(-Position, -GID, -YORF, -GWEIGHT))
# str(data_clean)
library(readr)
data <- read_csv("microarray_expression_data.csv", col_names = TRUE)
dim(data)
str(data)
library(tidyr)
data_clean <- separate(data = data, col = NAME, into = c("Name", "Function", "Details", "Mutation", "Position"), sep = "\\|\\|", remove = T)
library(dplyr)
library(stringr)
data_clean <- data_clean %>%
mutate(Name = str_squish(Name))
data_clean <- data_clean %>%
select(c(-Position, -GID, -YORF, -GWEIGHT))
# str(data_clean)
View(data_clean)
help("pivot_longer")
vignette("pivot")
relig_income
relig_income %>%
pivot_longer(
cols = !religion,
names_to = "income",
values_to = "count"
)
relig_income
relig_income %>%
pivot_longer(
cols = !religion,
names_to = "income",
values_to = "count"
)
relig_data <- relig_income
relig_data_clean <- relig_income %>%
pivot_longer(
cols = !religion,
names_to = "income",
values_to = "count"
)
View(relig_data)
View(relig_data_clean)
help("starts_with")
data_clean <- data_clean %>%
pivot_longer(
cols = starts_with("G0", "N0", "P0", "S0", "L0", "U0"),
names_to = "Info",
values_to = "Count"
)
data_clean <- data_clean %>%
pivot_longer(
cols = starts_with(c("G0", "N0", "P0", "S0", "L0", "U0")),
names_to = "Info",
values_to = "Count"
)
